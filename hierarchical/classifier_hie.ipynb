{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep Learning 相關\n",
    "import torch\n",
    "from torch import nn, optim, utils\n",
    "\n",
    "# 系統互動\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# 自訂部分\n",
    "from model_hie import ResNet50MothClassifier\n",
    "from dataset_hie import ImageDatasetFromFileSpecial\n",
    "from average_meter import AverageMeter\n",
    "from center_loss import CenterLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料 & 前處理\n",
    "dataset_path = 'sp_mod.csv'\n",
    "df = pd.read_csv(dataset_path, sep=\"\\t\")\n",
    "\n",
    "# 移除未鑑定到種的資料\n",
    "df = df[~df.Species.isna()].reset_index(drop=True)\n",
    "\n",
    "# Remove data without Genus or Family\n",
    "df = df[~df.Genus.isna()].reset_index(drop=True)\n",
    "df = df[~df.Family.isna()].reset_index(drop=True)\n",
    "\n",
    "# 造出物種清單，並產生每筆資料對應的物種 id, 視為 classification 用的 target y\n",
    "species_list, species_id = np.unique(df.Species, return_inverse=True)\n",
    "genus_list, genus_id = np.unique(df.Genus, return_inverse=True)\n",
    "family_list, family_id = np.unique(df.Family, return_inverse=True)\n",
    "y = np.array(list(zip(species_id, genus_id, family_id)))\n",
    "\n",
    "# 產生影像路徑\n",
    "x = img_paths = ('./downloaded256/' + df.Number + '.jpg').values\n",
    "\n",
    "opt_dataroot = \"./downloaded256/\"\n",
    "opt_batchSize = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切 train, valid, test\n",
    "x_train_valid, x_test, y_train_valid, y_test = train_test_split(x, y,  train_size=.8, test_size=.2, random_state=5566)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid,  train_size=.8, test_size=.2, random_state=5566)\n",
    "\n",
    "train_set = ImageDatasetFromFileSpecial(x_train, \"\", y=y_train, aug=True)\n",
    "train_data_loader = utils.data.DataLoader(train_set, batch_size=opt_batchSize, shuffle=True)\n",
    "\n",
    "# valid 與 test 時不需要做 augmentation\n",
    "valid_set = ImageDatasetFromFileSpecial(x_valid, \"\", y=y_valid, aug=False)\n",
    "valid_data_loader = utils.data.DataLoader(valid_set, batch_size=opt_batchSize, shuffle=False)\n",
    "\n",
    "# 儲存模型\n",
    "def save_checkpoint(model, model_out_path = \"resnet50_moth_classifier_hie.pth\"):\n",
    "    torch.save({\"model\": model}, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.3.0\n"
     ]
    }
   ],
   "source": [
    "# init model, 把模型搬進 GPU:0 的記憶體中\n",
    "model = ResNet50MothClassifier(num_of_species=len(species_list), num_of_genus=len(genus_list), num_of_family=len(family_list)).to('cuda:0')\n",
    "# 設定 optimizer\n",
    "# adam = optim.Adam(model.parameters(), lr=5e-5, betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "# 設定分類器用的 cross entropy loss\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize center loss and optimizers\n",
    "center_loss = CenterLoss(num_classes=len(species_list), feat_dim=len(species_list), use_gpu=True)\n",
    "adam = optim.Adam(model.parameters(), lr=5e-5, betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "centerloss_optimizer = optim.Adam(center_loss.parameters(), lr=5e-2, betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "centerloss_alpha = 0.005\n",
    "\n",
    "# init min loss criteria\n",
    "min_criteria = np.inf\n",
    "\n",
    "early_stop_threshold = 20\n",
    "early_stop_counter = 0\n",
    "\n",
    "# 開啟空白 log 檔\n",
    "with open('./resnet50_moth_classifier_hie.log','w') as loss_log:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Training Epoch[1](656/717); time:(0.30/1136.58); train loss:12.61\r"
     ]
    }
   ],
   "source": [
    "# 計算總花費時數\n",
    "start_time = time.time()\n",
    "for epoch in range(0, 200 + 1):  \n",
    "\n",
    "    # 簡單的平均值計算器\n",
    "    train_loss = AverageMeter()\n",
    "    valid_loss = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    #--------------train------------\n",
    "    model = model.train()\n",
    "    for iteration, (auged, label) in enumerate(train_data_loader, 0):\n",
    "        \n",
    "        batch_start_time = time.time()\n",
    "        auged_cuda = auged.to('cuda:0')\n",
    "        species_output, genus_output, family_output = model(auged_cuda)\n",
    "        # 注意在 model 中並沒有對輸出做 softmax\n",
    "        # 因為 pytorch 在 cross entropy loss 裡面有內建了\n",
    "        loss = center_loss(species_output, label[:, 0].to('cuda:0')) * centerloss_alpha + cross_entropy(species_output, label[:, 0].to('cuda:0')) + cross_entropy(genus_output, label[:, 1].to('cuda:0')) + cross_entropy(family_output, label[:, 2].to('cuda:0'))\n",
    "        # 將前次的梯度歸零\n",
    "        adam.zero_grad()\n",
    "        centerloss_optimizer.zero_grad()\n",
    "        # 計算本次的梯度\n",
    "        loss.backward()\n",
    "        # 更新模型參數\n",
    "        adam.step()\n",
    "        # multiple (1./alpha) in order to remove the effect of alpha on updating centers\n",
    "        for param in center_loss.parameters():\n",
    "            param.grad.data *= (1. / centerloss_alpha)\n",
    "        centerloss_optimizer.step()\n",
    "        \n",
    "        # 計算花費時數\n",
    "        time_cost = time.time() - start_time\n",
    "        batch_time_cost = time.time() - batch_start_time\n",
    "        batch_time.update(batch_time_cost)\n",
    "        \n",
    "        # 紀錄 training loss per batch in a epoch\n",
    "        train_loss.update(loss.item())\n",
    "\n",
    "        info = \"====> Training Epoch[{}]({}/{}); time:({:.2f}/{:.2f}); train loss:{:.2f}\".format(epoch+1, iteration+1, len(train_data_loader), batch_time.avg, time_cost, train_loss.avg)\n",
    "        print(info, end='\\r')\n",
    "        \n",
    "        del auged_cuda, species_output, genus_output, family_output\n",
    "    \n",
    "    #print()\n",
    "\n",
    "    #--------------valid------------\n",
    "    batch_time = AverageMeter()\n",
    "    # 將模型設置成 eval 模式，固定住 weights, bias 等參數 (包括 batch norm)\n",
    "    model = model.eval()\n",
    "    for iteration, (img_for_valid, label) in enumerate(valid_data_loader, 0):\n",
    "\n",
    "        batch_start_time = time.time()\n",
    "        img_for_valid_cuda = img_for_valid.to('cuda:0')\n",
    "        species_output, genus_output, family_output = model(img_for_valid_cuda)\n",
    "\n",
    "        loss = center_loss(species_output, label[:, 0].to('cuda:0')) * centerloss_alpha + cross_entropy(species_output, label[:, 0].to('cuda:0')) + cross_entropy(genus_output, label[:, 1].to('cuda:0')) + cross_entropy(family_output, label[:, 2].to('cuda:0'))\n",
    "\n",
    "        time_cost = time.time() - start_time\n",
    "        batch_time_cost = time.time() - batch_start_time\n",
    "        batch_time.update(batch_time_cost)\n",
    "\n",
    "        # 紀錄 valid loss per batch in a epoch\n",
    "        valid_loss.update(loss.item())\n",
    "\n",
    "        info = \"====> Validation ({}/{}): time:({:.2f}/{:.2f}): valid loss:{:.2f}\".format(iteration+1, len(valid_data_loader), batch_time.avg, time_cost, valid_loss.avg)\n",
    "        print(info, end='\\r')\n",
    "\n",
    "        del img_for_valid_cuda, species_output, genus_output, family_output\n",
    "\n",
    "    #print()    \n",
    "\n",
    "    valid_loss_avg = valid_loss.avg\n",
    "\n",
    "    criteria = valid_loss_avg\n",
    "\n",
    "    # 如果 loss 差值太小無實質意義，可用 min_delta 控制\n",
    "    min_delta = 0\n",
    "    if min_criteria - criteria >= min_delta:\n",
    "        min_criteria = criteria\n",
    "        print (\"Min criteria: %.2f\" % min_criteria)\n",
    "        save_checkpoint(model, model_out_path = \"resnet50_moth_classifier.pth\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print (\"Early stop counter: %d\" % early_stop_counter)\n",
    "\n",
    "    if early_stop_counter > early_stop_threshold:\n",
    "        print (\"Early stopped.\")\n",
    "        break\n",
    "\n",
    "    with open('./resnet50_moth_classifier.log','a') as loss_log:\n",
    "        loss_log.write(\n",
    "            \"\\t\".join([\n",
    "                str(epoch+1), \n",
    "                '%.2f' % time_cost,\n",
    "                '%.6f' % train_loss.avg,\n",
    "                '%.6f' % valid_loss.avg,\n",
    "                '\\n',\n",
    "            ])\n",
    "        )\n",
    "\n",
    "# 沒寫 test 的部分，可以先自己試想試做看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
