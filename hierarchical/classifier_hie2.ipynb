{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Training Epoch[1](713/713); time:(0.31/484.56); train loss:13.24; center:0.85; species:6.18; genus:5.08; family:1.14\n",
      "====> Validation (180/180): time:(0.09/518.02): valid loss:9.30; center:0.55; species:4.74; genus:3.45; family:0.55\n",
      "Min criteria: 9.30\n",
      "Checkpoint saved to resnet50_moth_classifier_hie.pth\n",
      "====> Training Epoch[2](713/713); time:(0.31/1001.99); train loss:7.57; center:0.68; species:3.95; genus:2.58; family:0.36\n",
      "====> Validation (180/180): time:(0.09/1035.56): valid loss:5.91; center:0.76; species:3.16; genus:1.79; family:0.20\n",
      "Min criteria: 5.91\n",
      "Checkpoint saved to resnet50_moth_classifier_hie.pth\n",
      "====> Training Epoch[3](713/713); time:(0.31/1519.81); train loss:5.18; center:0.72; species:2.81; genus:1.46; family:0.18\n",
      "====> Validation (180/180): time:(0.09/1553.19): valid loss:4.39; center:0.77; species:2.37; genus:1.11; family:0.14\n",
      "Min criteria: 4.39\n",
      "Checkpoint saved to resnet50_moth_classifier_hie.pth\n",
      "====> Training Epoch[4](423/713); time:(0.31/1840.23); train loss:4.04; center:0.70; species:2.23; genus:0.99; family:0.12\r"
     ]
    }
   ],
   "source": [
    "# 基礎資料處理切分\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep Learning 相關\n",
    "import torch\n",
    "from torch import nn, optim, utils\n",
    "\n",
    "# 系統互動\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# 自訂部分\n",
    "from model_hie import ResNet50MothClassifier\n",
    "from dataset_hie import ImageDatasetFromFileSpecial\n",
    "from average_meter import AverageMeter\n",
    "from center_loss import CenterLoss\n",
    "\n",
    "opt_dataroot = \"./downloaded256/\"\n",
    "opt_batchSize = 48\n",
    "\n",
    "# 讀取資料 & 前處理\n",
    "dataset_path = 'sp_meta.csv'\n",
    "df = pd.read_csv(dataset_path, sep=\"\\t\")\n",
    "\n",
    "# 移除未鑑定到種的資料\n",
    "df = df[~df.Species.isna()].reset_index(drop=True)\n",
    "\n",
    "genus = [s.split(' ')[0] for s in df.Species]\n",
    "df['Genus'] = genus\n",
    "\n",
    "# 造出物種清單，並產生每筆資料對應的物種 id, 視為 classification 用的 target y\n",
    "species_list, species_id = np.unique(df.Species, return_inverse=True)\n",
    "family_list, family_id = np.unique(df.Family, return_inverse=True)\n",
    "genus_list, genus_id = np.unique(df.Genus, return_inverse=True)\n",
    "\n",
    "x_train = np.load('./datasplit_cache/x_train.npy', allow_pickle=True)\n",
    "y_train = np.load('./datasplit_cache/y_train.npy', allow_pickle=True)\n",
    "x_valid = np.load('./datasplit_cache/x_valid.npy', allow_pickle=True)\n",
    "y_valid = np.load('./datasplit_cache/y_valid.npy', allow_pickle=True)\n",
    "x_test = np.load('./datasplit_cache/x_test.npy', allow_pickle=True)\n",
    "y_test = np.load('./datasplit_cache/y_test.npy', allow_pickle=True)\n",
    "\n",
    "x_train_new = [f'./downloaded256/{pth.split(\"/\")[-1]}' for pth in x_train]\n",
    "x_valid_new = [f'./downloaded256/{pth.split(\"/\")[-1]}' for pth in x_valid]\n",
    "x_test_new = [f'./downloaded256/{pth.split(\"/\")[-1]}' for pth in x_test]\n",
    "# 需要把 x 裡的路徑修改成雲端的路徑\n",
    "# 寫法例如 x_train_new = [('./path/to/images/%s' % f.split('/')[-1]) for f in x_train]\n",
    "# y 是 label, 但順序跟你原本用的相反，0 是 family, 1 是 genus, 2 是 species\n",
    "\n",
    "\n",
    "'''\n",
    "# 讀取資料 & 前處理\n",
    "dataset_path = 'sp_mod.csv'\n",
    "df = pd.read_csv(dataset_path, sep=\"\\t\")\n",
    "\n",
    "# 移除未鑑定到種的資料\n",
    "df = df[~df.Species.isna()].reset_index(drop=True)\n",
    "\n",
    "# Remove data without Genus or Family\n",
    "df = df[~df.Genus.isna()].reset_index(drop=True)\n",
    "df = df[~df.Family.isna()].reset_index(drop=True)\n",
    "\n",
    "# 造出物種清單，並產生每筆資料對應的物種 id, 視為 classification 用的 target y\n",
    "species_list, species_id = np.unique(df.Species, return_inverse=True)\n",
    "genus_list, genus_id = np.unique(df.Genus, return_inverse=True)\n",
    "family_list, family_id = np.unique(df.Family, return_inverse=True)\n",
    "y = np.array(list(zip(species_id, genus_id, family_id)))\n",
    "\n",
    "# 產生影像路徑\n",
    "x = img_paths = ('./downloaded256/' + df.Number + '.jpg').values\n",
    "\n",
    "# 切 train, valid, test\n",
    "x_train_valid, x_test, y_train_valid, y_test = train_test_split(x, y,  train_size=.8, test_size=.2, random_state=5566)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid,  train_size=.8, test_size=.2, random_state=5566)\n",
    "'''\n",
    "\n",
    "train_set = ImageDatasetFromFileSpecial(x_train_new, \"\", y=y_train, aug=True)\n",
    "train_data_loader = utils.data.DataLoader(train_set, batch_size=opt_batchSize, shuffle=True)\n",
    "\n",
    "# valid 與 test 時不需要做 augmentation\n",
    "valid_set = ImageDatasetFromFileSpecial(x_valid_new, \"\", y=y_valid, aug=False)\n",
    "valid_data_loader = utils.data.DataLoader(valid_set, batch_size=opt_batchSize, shuffle=False)\n",
    "\n",
    "# 儲存模型\n",
    "def save_checkpoint(model, model_out_path = \"resnet50_moth_classifier_hie.pth\"):\n",
    "    torch.save({\"model\": model}, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "\n",
    "# init model, 把模型搬進 GPU:0 的記憶體中\n",
    "model = ResNet50MothClassifier(num_of_species=len(species_list), num_of_genus=len(genus_list), num_of_family=len(family_list)).to('cuda:0')\n",
    "# 設定 optimizer\n",
    "# adam = optim.Adam(model.parameters(), lr=5e-5, betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "# 設定分類器用的 cross entropy loss\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize center loss and optimizers\n",
    "center_loss = CenterLoss(num_classes=len(species_list), feat_dim=2048, use_gpu=True)\n",
    "adam = optim.Adam(model.parameters(), lr=5e-5, betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "centerloss_optimizer = optim.Adam(center_loss.parameters(), lr=5e-2, betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "centerloss_alpha = 0.005\n",
    "\n",
    "# init min loss criteria\n",
    "min_criteria = np.inf\n",
    "\n",
    "early_stop_threshold = 50\n",
    "early_stop_counter = 0\n",
    "\n",
    "# 開啟空白 log 檔\n",
    "with open('./resnet50_moth_classifier_hie.log','w') as loss_log:\n",
    "    loss_log.write(\n",
    "            \"\\t\".join([\n",
    "                '%5s' % 'epoch', \n",
    "                '%10s' % 'time_cost',\n",
    "                '%10s' % 'train_loss',\n",
    "                '%10s' % 'valid_loss',\n",
    "                '%10s' % 't_center',\n",
    "                '%10s' % 't_species',\n",
    "                '%10s' % 't_genus',\n",
    "                '%10s' % 't_family',\n",
    "                '%10s' % 'v_center',\n",
    "                '%10s' % 'v_species',\n",
    "                '%10s' % 'v_genus',\n",
    "                '%10s' % 'v_family',\n",
    "                '\\n',\n",
    "            ])\n",
    "        )\n",
    "\n",
    "# 計算總花費時數\n",
    "start_time = time.time()\n",
    "for epoch in range(0, 200 + 1):  \n",
    "\n",
    "    # 簡單的平均值計算器\n",
    "    train_loss = AverageMeter()\n",
    "    train_loss_ctr = AverageMeter()\n",
    "    train_loss_spc = AverageMeter()\n",
    "    train_loss_gns = AverageMeter()\n",
    "    train_loss_fml = AverageMeter()\n",
    "    valid_loss = AverageMeter()\n",
    "    valid_loss_ctr = AverageMeter()\n",
    "    valid_loss_spc = AverageMeter()\n",
    "    valid_loss_gns = AverageMeter()\n",
    "    valid_loss_fml = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    #--------------train------------\n",
    "    model = model.train()\n",
    "    center_loss = center_loss.train()\n",
    "    for iteration, (auged, label) in enumerate(train_data_loader, 0):\n",
    "        \n",
    "        batch_start_time = time.time()\n",
    "        auged_cuda = auged.to('cuda:0')\n",
    "        feat, species_output, genus_output, family_output = model(auged_cuda)\n",
    "        # 注意在 model 中並沒有對輸出做 softmax\n",
    "        # 因為 pytorch 在 cross entropy loss 裡面有內建了\n",
    "        ctr_loss = center_loss(feat.view(-1, 2048), label[:, 2].to('cuda:0')) * centerloss_alpha\n",
    "        spc_loss = cross_entropy(species_output, label[:, 2].to('cuda:0'))\n",
    "        gns_loss = cross_entropy(genus_output, label[:, 1].to('cuda:0'))\n",
    "        fml_loss = cross_entropy(family_output, label[:, 0].to('cuda:0'))\n",
    "        loss = ctr_loss + spc_loss + gns_loss + fml_loss\n",
    "        # 將前次的梯度歸零\n",
    "        adam.zero_grad()\n",
    "        centerloss_optimizer.zero_grad()\n",
    "        # 計算本次的梯度\n",
    "        loss.backward()\n",
    "        # 更新模型參數\n",
    "        adam.step()\n",
    "        # multiple (1./alpha) in order to remove the effect of alpha on updating centers\n",
    "        for param in center_loss.parameters():\n",
    "            param.grad.data *= (1. / centerloss_alpha)\n",
    "        centerloss_optimizer.step()\n",
    "        \n",
    "        # 計算花費時數\n",
    "        time_cost = time.time() - start_time\n",
    "        batch_time_cost = time.time() - batch_start_time\n",
    "        batch_time.update(batch_time_cost)\n",
    "        \n",
    "        # 紀錄 training loss per batch in a epoch\n",
    "        train_loss.update(loss.item())\n",
    "        train_loss_ctr.update(ctr_loss.item())\n",
    "        train_loss_spc.update(spc_loss.item())\n",
    "        train_loss_gns.update(gns_loss.item())\n",
    "        train_loss_fml.update(fml_loss.item())\n",
    "\n",
    "        info = \"====> Training Epoch[{}]({}/{}); time:({:.2f}/{:.2f}); train loss:{:.2f}; center:{:.2f}; species:{:.2f}; genus:{:.2f}; family:{:.2f}\".format(epoch+1, iteration+1, len(train_data_loader), batch_time.avg, time_cost, train_loss.avg, train_loss_ctr.avg, train_loss_spc.avg, train_loss_gns.avg, train_loss_fml.avg)\n",
    "        print(info, end='\\r')\n",
    "        \n",
    "        del auged_cuda, species_output, genus_output, family_output\n",
    "    \n",
    "    print()\n",
    "\n",
    "    #--------------valid------------\n",
    "    with torch.no_grad():\n",
    "        batch_time = AverageMeter()\n",
    "        # 將模型設置成 eval 模式，固定住 weights, bias 等參數 (包括 batch norm)\n",
    "        model = model.eval()\n",
    "        center_loss = center_loss.eval()\n",
    "        for iteration, (img_for_valid, label) in enumerate(valid_data_loader, 0):\n",
    "\n",
    "            batch_start_time = time.time()\n",
    "            img_for_valid_cuda = img_for_valid.to('cuda:0')\n",
    "            feat, species_output, genus_output, family_output = model(img_for_valid_cuda)\n",
    "\n",
    "            ctr_loss = center_loss(feat.view(-1, 2048), label[:, 2].to('cuda:0')) * centerloss_alpha\n",
    "            spc_loss = cross_entropy(species_output, label[:, 2].to('cuda:0'))\n",
    "            gns_loss = cross_entropy(genus_output, label[:, 1].to('cuda:0'))\n",
    "            fml_loss = cross_entropy(family_output, label[:, 0].to('cuda:0'))\n",
    "            loss = ctr_loss + spc_loss + gns_loss + fml_loss\n",
    "\n",
    "            time_cost = time.time() - start_time\n",
    "            batch_time_cost = time.time() - batch_start_time\n",
    "            batch_time.update(batch_time_cost)\n",
    "            \n",
    "            # 紀錄 valid loss per batch in a epoch\n",
    "            valid_loss.update(loss.item())\n",
    "            valid_loss_ctr.update(ctr_loss.item())\n",
    "            valid_loss_spc.update(spc_loss.item())\n",
    "            valid_loss_gns.update(gns_loss.item())\n",
    "            valid_loss_fml.update(fml_loss.item())\n",
    "\n",
    "            info = \"====> Validation ({}/{}): time:({:.2f}/{:.2f}): valid loss:{:.2f}; center:{:.2f}; species:{:.2f}; genus:{:.2f}; family:{:.2f}\".format(iteration+1, len(valid_data_loader), batch_time.avg, time_cost, valid_loss.avg, valid_loss_ctr.avg, valid_loss_spc.avg, valid_loss_gns.avg, valid_loss_fml.avg)\n",
    "            print(info, end='\\r')\n",
    "\n",
    "            del img_for_valid_cuda, species_output, genus_output, family_output\n",
    "    \n",
    "    print()    \n",
    "\n",
    "    valid_loss_avg = valid_loss.avg\n",
    "\n",
    "    criteria = valid_loss_avg\n",
    "\n",
    "    # 如果 loss 差值太小無實質意義，可用 min_delta 控制\n",
    "    min_delta = 0\n",
    "    if min_criteria - criteria >= min_delta:\n",
    "        min_criteria = criteria\n",
    "        print (\"Min criteria: %.2f\" % min_criteria)\n",
    "        save_checkpoint(model, model_out_path = \"resnet50_moth_classifier_hie.pth\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print (\"Early stop counter: %d\" % early_stop_counter)\n",
    "\n",
    "    if early_stop_counter > early_stop_threshold:\n",
    "        print (\"Early stopped.\")\n",
    "        break\n",
    "\n",
    "    with open('./resnet50_moth_classifier_hie.log','a') as loss_log:\n",
    "        loss_log.write(\n",
    "            \"\\t\".join([\n",
    "                '%5s' % str(epoch+1), \n",
    "                '%10.2f' % time_cost,\n",
    "                '%10.6f' % train_loss.avg,\n",
    "                '%10.6f' % valid_loss.avg,\n",
    "                '%10.6f' % train_loss_ctr.avg,\n",
    "                '%10.6f' % train_loss_spc.avg,\n",
    "                '%10.6f' % train_loss_gns.avg,\n",
    "                '%10.6f' % train_loss_fml.avg,\n",
    "                '%10.6f' % valid_loss_ctr.avg,\n",
    "                '%10.6f' % valid_loss_spc.avg,\n",
    "                '%10.6f' % valid_loss_gns.avg,\n",
    "                '%10.6f' % valid_loss_fml.avg,\n",
    "                '\\n',\n",
    "            ])\n",
    "        )\n",
    "\n",
    "# 沒寫 test 的部分，可以先自己試想試做看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
